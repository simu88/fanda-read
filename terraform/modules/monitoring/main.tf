# 1. ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±
resource "kubernetes_namespace" "monitoring" {
  metadata {
    name = "fanda-monitoring"
  }
}


# 2. Prometheus ì„¤ì¹˜
resource "helm_release" "prometheus" {
  name          = "prometheus-stack"
  repository    = "https://prometheus-community.github.io/helm-charts"
  chart         = "kube-prometheus-stack"
  namespace     = kubernetes_namespace.monitoring.metadata[0].name
  version       = "76.4.0" # ê²€ì¦ëœ ìµœì‹  ì•ˆì • ë²„ì „
  recreate_pods = true

  values = [
    yamlencode({
      prometheus = {
        service = {
          type = "LoadBalancer"
          port : 80
          targetPort : 9090
          # [ë³´ì•ˆ ê¶Œì¥] íŠ¹ì • IP ëŒ€ì—­ì—ì„œë§Œ ì ‘ê·¼ì„ í—ˆìš©í•©ë‹ˆë‹¤. (Grafana ì„¤ì •ê³¼ ë™ì¼í•˜ê²Œ ì ìš©)
          # loadBalancerSourceRanges = [
          #   "118.218.200.33/32", # ì‚¬ë¬´ì‹¤
          #   "58.78.119.14/32",   # ì§‘
          #   "211.179.27.76/32",  # ì¹´í˜
          #   "211.60.226.136/32"  # ì •ë¯¼ ì¬íƒ
          # ]

          annotations = {
            "service.beta.kubernetes.io/aws-load-balancer-type"             = "nlb",
            "service.beta.kubernetes.io/aws-load-balancer-scheme"           = "internet-facing",
            "service.beta.kubernetes.io/aws-load-balancer-healthcheck-path" = "/-/healthy",
            "service.beta.kubernetes.io/aws-load-balancer-healthcheck-port" = "traffic-port"

          }


        }


        prometheusSpec = {
          retention = "7d"
          storageSpec = {
            volumeClaimTemplate = {
              spec = {
                storageClassName = var.storage_class_name
                accessModes      = ["ReadWriteOnce"]
                resources        = { requests = { storage = "20Gi" } }
              }
            }
          }
        }

        # EKSì—ì„œëŠ” kubeControllerManager/kubeScheduler Rule ì œê±°
        additionalPrometheusRulesMap = {
          "kubernetes-system-controller-manager" = null
          "kubernetes-system-scheduler"          = null
        }

      }

      kubeControllerManager = { enabled = false }
      kubeScheduler         = { enabled = false }

      alertmanager = {
        enabled = true
        service = {
          type       = "LoadBalancer"
          port       = 80
          targetPort = 9093
          # [ë³´ì•ˆ ê¶Œì¥] Prometheusì™€ ë™ì¼í•˜ê²Œ ì ‘ê·¼ ì œì–´ ì„¤ì •
          # loadBalancerSourceRanges = [
          #   "118.218.200.33/32",
          #   "58.78.119.14/32",
          #   "211.179.27.76/32",
          #   "211.60.226.136/32" #ì •ë¯¼
          # ]

          annotations = {
            "service.beta.kubernetes.io/aws-load-balancer-type"             = "nlb",
            "service.beta.kubernetes.io/aws-load-balancer-scheme"           = "internet-facing",
            "service.beta.kubernetes.io/aws-load-balancer-healthcheck-path" = "/-/healthy",
            "service.beta.kubernetes.io/aws-load-balancer-healthcheck-port" = "traffic-port"

          }
        }
        # Alertmanager Config
        config = {
          global = {
            resolve_timeout    = "5m"
            slack_api_url_file = "/etc/alertmanager/secrets/alertmanager-slack-secret/slack-url"
          }

          route = {
            receiver        = "slack-notifications"
            group_by        = ["job", "alertname"]
            group_wait      = "30s"
            group_interval  = "5m"
            repeat_interval = "1h"
            routes = [
              {
                receiver = "null"
                matchers = ["alertname = Watchdog"]
              }
            ]
          }

          receivers = [
            {
              name = "slack-notifications"
              slack_configs = [
                {
                  channel       = "#ëª¨ë‹ˆí„°ë§-ì•ŒëŒ-eks"
                  send_resolved = true
                  title         = "{{ .CommonLabels.alertname }} - {{ .Status | toUpper }}"
                  text          = <<-EOT
              {{- range .Alerts }}
              *Summary:* {{ .Annotations.summary }}
              *Description:* {{ .Annotations.description }}
              *Details:*
              {{- range .Labels.SortedPairs }}
               - `{{ .Name }}` = `{{ .Value }}`
              {{- end }}
              {{- end }}
            EOT
                }
              ]
            },
            { name = "null" }
          ]
        }

        # Alertmanager Pod Spec
        alertmanagerSpec = {
          # chart ê³µì‹ ì§€ì› í•„ë“œë¡œ Secret ë§ˆìš´íŠ¸
          secrets = ["alertmanager-slack-secret"]

        }
      }



      grafana = {
        enabled = false
      }
    })
  ]

  depends_on = [kubernetes_namespace.monitoring]
}




data "aws_caller_identity" "current" {}

resource "aws_s3_bucket" "fanda_monitoring_bucket" {
  # ë²„í‚· ì´ë¦„ì€ ì „ì—­ì ìœ¼ë¡œ ê³ ìœ í•´ì•¼ í•˜ë¯€ë¡œ ê³„ì • ID ë“±ì„ ì ‘ë¯¸ì‚¬ë¡œ ì¶”ê°€í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.
  bucket        = "fanda-monitoring-bucket-${data.aws_caller_identity.current.account_id}"
  force_destroy = true

  tags = {
    Name = "fanda-monitoring-bucket"
  }
}

# # S3 ë²„í‚·ì— Lokiê°€ ì‚¬ìš©í•  ì´ˆê¸° í´ë” êµ¬ì¡° ìƒì„± (ì„ íƒ ì‚¬í•­)
# resource "aws_s3_object" "folders" {
#   for_each = {
#     "loki/chunks/" = "" # ì²­í¬(ë¡œê·¸ ë°ì´í„°) ì €ì¥ ê²½ë¡œ
#     "loki/ruler/"  = "" # ì•Œë¦¼ ê·œì¹™ ì €ì¥ ê²½ë¡œ
#     "loki/admin/"  = "" # ê´€ë¦¬ ë©”íƒ€ë°ì´í„° ì €ì¥
#   }

#   bucket  = aws_s3_bucket.fanda_monitoring_bucket.bucket
#   key     = each.key
#   content = each.value # ë¹ˆ ê°ì²´ë¥¼ ìƒì„±í•˜ì—¬ í´ë”ì²˜ëŸ¼ ë³´ì´ê²Œ í•¨
# }



# Lokiê°€ S3 ë²„í‚·ì— ì ‘ê·¼í•˜ëŠ”ë° í•„ìš”í•œ ê¶Œí•œì„ ì •ì˜í•˜ëŠ” IAM ì •ì±…
resource "aws_iam_policy" "loki_s3_policy" {
  name        = "loki-s3-access-policy"
  description = "Allows Loki to read/write/list/delete objects in its S3 bucket"

  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      # {
      #   Effect = "Allow",
      #   Action = [
      #     "s3:PutObject",
      #     "s3:GetObject",
      #     "s3:DeleteObject"
      #   ],
      #   # Lokiê°€ íŠ¹ì • ê²½ë¡œ í•˜ìœ„ì—ë§Œ ê°ì²´ë¥¼ ìƒì„±/ì¡°íšŒ/ì‚­ì œí•˜ë„ë¡ ê¶Œí•œì„ ì œí•œí•©ë‹ˆë‹¤.
      #   Resource = "${aws_s3_bucket.fanda_monitoring_bucket.arn}/loki/*"
      # },
      # {
      #   Effect   = "Allow",
      #   Action   = "s3:ListBucket",
      #   Resource = aws_s3_bucket.fanda_monitoring_bucket.arn,
      #   # Lokiê°€ ë²„í‚· ë‚´ ê°ì²´ ëª©ë¡ì„ ì¡°íšŒí•  ìˆ˜ ìˆë„ë¡ í—ˆìš©í•©ë‹ˆë‹¤.
      #   Condition = {
      #     StringLike = {
      #       "s3:prefix" = ["loki/*"]
      #     }
      #   }
      # }
      {
        "Effect" : "Allow",
        "Action" : [
          "s3:ListBucket",
          "s3:PutObject",
          "s3:GetObject",
          "s3:DeleteObject"
        ],
        "Resource" : [
          "${aws_s3_bucket.fanda_monitoring_bucket.arn}",
          "${aws_s3_bucket.fanda_monitoring_bucket.arn}/*"
        ]
      }

    ]

  })
}


# Loki íŒŒë“œì˜ ì„œë¹„ìŠ¤ ì–´ì¹´ìš´íŠ¸ê°€ ìœ„ì„ë°›ì„ IAM ì—­í• 
resource "aws_iam_role" "loki_s3_role" {
  name = "loki-s3-role"

  # ì´ ì—­í• ì„ ìœ„ì„ë°›ì„ ìˆ˜ ìˆëŠ” ì£¼ì²´(Principal)ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
  # EKS OIDC ê³µê¸‰ìë¥¼ ì‹ ë¢°í•˜ê³ , íŠ¹ì • ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì™€ ì„œë¹„ìŠ¤ ì–´ì¹´ìš´íŠ¸ ì´ë¦„ì¼ ê²½ìš°ì—ë§Œ í—ˆìš©í•©ë‹ˆë‹¤.
  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Effect = "Allow",
        Principal = {
          Federated = var.oidc_provider_arn
        },
        Action = "sts:AssumeRoleWithWebIdentity",
        Condition = {
          StringEquals = {
            # "fanda-monitoring" ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ "loki" ì„œë¹„ìŠ¤ ì–´ì¹´ìš´íŠ¸ë§Œ ì´ ì—­í• ì„ ìœ„ì„ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            "${var.oidc_provider_url}:sub" = "system:serviceaccount:fanda-monitoring:loki"
          }
        }
      }
    ]
  })
}

# ìƒì„±í•œ IAM ì—­í• ì— S3 ì ‘ê·¼ ì •ì±…ì„ ì—°ê²°í•©ë‹ˆë‹¤.
resource "aws_iam_role_policy_attachment" "loki_s3_attachment" {
  role       = aws_iam_role.loki_s3_role.name
  policy_arn = aws_iam_policy.loki_s3_policy.arn
}




### Loki Helm ì°¨íŠ¸ ë°°í¬- simpleScalableëª¨ë“œ 
resource "helm_release" "loki" {
  name       = "loki"
  namespace  = "fanda-monitoring"
  repository = "https://grafana.github.io/helm-charts"
  chart      = "loki"
  version    = "6.38.0"

  recreate_pods   = true
  cleanup_on_fail = true
  wait            = true
  timeout         = 300

  values = [
    yamlencode({
      # 1ï¸âƒ£ ì„œë¹„ìŠ¤ ì–´ì¹´ìš´íŠ¸ + IRSA
      serviceAccount = {
        create = true
        name   = "loki"
        annotations = {
          "eks.amazonaws.com/role-arn" = aws_iam_role.loki_s3_role.arn
        }
      }

      # 2ï¸âƒ£ ë°°í¬ ëª¨ë“œ: SimpleScalable
      deploymentMode = "SimpleScalable"

      # 3ï¸âƒ£ Loki í•µì‹¬ ì„¤ì •
      loki = {
        schemaConfig = {
          configs = [
            {
              from         = "2024-04-01"
              store        = "tsdb"
              object_store = "s3"
              schema       = "v13"
              index        = { prefix = "loki_index_", period = "24h" }
            }
          ]
        }

        storage_config = {
          aws = {
            region           = var.region
            bucketnames      = aws_s3_bucket.fanda_monitoring_bucket.bucket
            s3forcepathstyle = false
          }
        }

        storage = {
          type = "s3"
          bucketNames = {
            chunks = "${aws_s3_bucket.fanda_monitoring_bucket.bucket}/loki/chunks"
            ruler  = "${aws_s3_bucket.fanda_monitoring_bucket.bucket}/loki/ruler"
            admin  = "${aws_s3_bucket.fanda_monitoring_bucket.bucket}/loki/admin"
          }
          s3 = {
            region           = var.region
            signatureVersion = "v4"
            s3ForcePathStyle = false
            insecure         = false
            http_config      = {}
          }
        }

        pattern_ingester = { enabled = true }

        limits_config = {
          allow_structured_metadata = true
          volume_enabled            = true
          retention_period          = "672h" # 28ì¼
        }

        querier = { max_concurrent = 4 }
      }

      # 4ï¸âƒ£ ì»´í¬ë„ŒíŠ¸ ë³µì œ ìˆ˜
      backend = { replicas = 3 }
      read    = { replicas = 3 }
      write   = { replicas = 3 }

      # 5ï¸âƒ£ minio ë¹„í™œì„±í™”
      minio = { enabled = false }

      # 6ï¸âƒ£ server readiness probe
      server = {
        http_listen_port          = 3100
        grpc_listen_port          = 9095
        http_server_read_timeout  = "600s"
        http_server_write_timeout = "600s"
        readinessProbe = {
          httpGet = {
            path = "/ready"
            port = 3100
          }
          initialDelaySeconds = 30
          periodSeconds       = 10
          timeoutSeconds      = 1
          failureThreshold    = 5
        }
      }

      # # 7ï¸âƒ£ gateway ì„¤ì • (ì™¸ë¶€ Grafana ì—°ê²° ê°€ëŠ¥)
      # gateway = {
      #   service = { type = "LoadBalancer" }
      # }
    })
  ]

  depends_on = [
    aws_s3_bucket.fanda_monitoring_bucket,
    aws_iam_role_policy_attachment.loki_s3_attachment
  ]
}





# # 3. Loki Helm ì°¨íŠ¸ ë°°í¬ (S3 ì €ì¥ì†Œ ë° IRSA ì„¤ì • ì ìš©)
# resource "helm_release" "loki" {
#   name       = "loki"
#   namespace  = "fanda-monitoring"
#   repository = "https://grafana.github.io/helm-charts"
#   chart      = "loki"
#   version    = "6.5.1"

#   recreate_pods   = true
#   cleanup_on_fail = true
#   wait            = true
#   timeout         = 300 # ğŸ”¹ readiness ì§€ì—°ì„ ê³ ë ¤í•´ timeout ì—°ì¥

#   values = [
#     yamlencode({
#       # 1ï¸âƒ£ IRSA ì ìš© ì„œë¹„ìŠ¤ ì–´ì¹´ìš´íŠ¸
#       serviceAccount = {
#         create = true
#         name   = "loki"
#         annotations = {
#           "eks.amazonaws.com/role-arn" = aws_iam_role.loki_s3_role.arn
#         }
#       }

#       # 2ï¸âƒ£ multi Pod ëª¨ë“œ í™œì„±í™”
#       singleBinary = { enabled = false } # ğŸ”¹ ìˆ˜ì •: singleBinary â†’ false

#       # write          = { replicas = 1, persistence = { enabled = false } }
#       # read           = { replicas = 1 }
#       # backend        = { replicas = 1 }
#       # gateway        = { replicas = 1 }
#       # compactor      = { replicas = 1 }
#       # distributor    = { replicas = 1 }
#       # queryScheduler = { replicas = 1 }

#       # 5ï¸âƒ£ ìºì‹œ ê´€ë ¨
#       chunksCache = {
#         enabled = true
#         memcached = {
#           replicas = 1
#           resources = {
#             requests = { cpu = "200m", memory = "1Gi" }
#             limits   = { cpu = "500m", memory = "2Gi" }
#           }
#         }
#       }
#       resultsCache = { enabled = false }

#       # 6ï¸âƒ£ Loki í•µì‹¬ ì„¤ì • (S3 ìŠ¤í† ë¦¬ì§€)
#       loki = {
#         deploymentMode = "distributed"
#         storage = {
#           type = "s3"
#           bucketNames = {
#             chunks = "loki/chunks"
#             ruler  = "loki/ruler"
#             admin  = "loki/admin"
#           }
#           s3 = {
#             bucketnames = aws_s3_bucket.fanda_monitoring_bucket.bucket
#             # region           = var.region
#             region           = "us-east-1"
#             endpoint         = "s3.us-east-1.amazonaws.com"
#             s3ForcePathStyle = false
#           }
#         }

#         schemaConfig = {
#           configs = [
#             {
#               from         = "2025-07-01"
#               store        = "tsdb"
#               object_store = "s3"
#               schema       = "v13"
#               index        = { prefix = "index_", period = "24h" }
#             }
#           ]
#         }

#         limits_config = {
#           allow_structured_metadata     = true
#           max_cache_freshness_per_query = "10m"
#           query_timeout                 = "300s"
#           reject_old_samples            = true
#           reject_old_samples_max_age    = "168h"
#           split_queries_by_interval     = "15m"
#           volume_enabled                = true
#         }

#         validation = {
#           allow_structured_metadata = true
#         }

#         memberlistConfig = {
#           join_members = ["loki-memberlist"]
#         }
#       }

#       # 7ï¸âƒ£ readiness probe ìˆ˜ì • (503 ë°©ì§€) ğŸ”¹
#       server = {
#         http_listen_port          = 3100
#         grpc_listen_port          = 9095
#         http_server_read_timeout  = "600s"
#         http_server_write_timeout = "600s"
#         readinessProbe = {
#           httpGet = {
#             path = "/ready"
#             port = 3100
#           }
#           initialDelaySeconds = 30
#           periodSeconds       = 10
#           timeoutSeconds      = 1
#           failureThreshold    = 5
#         }
#       }
#     })
#   ]

#   depends_on = [
#     aws_s3_bucket.fanda_monitoring_bucket,
#     aws_iam_role_policy_attachment.loki_s3_attachment
#   ]
# }





# 4. Tempo ì„¤ì¹˜
resource "helm_release" "tempo" {
  name          = "tempo"
  repository    = "https://grafana.github.io/helm-charts"
  chart         = "tempo"
  namespace     = kubernetes_namespace.monitoring.metadata[0].name
  version       = "1.8.0"
  recreate_pods = true

  values = [
    yamlencode({
      persistence : {
        enabled : true
        storageClassName : var.storage_class_name
        accessModes : ["ReadWriteOnce"]
        size : "20Gi"
      }
      traces : { otlp : { grpc : { enabled : true }, http : { enabled : true } } }
    })
  ]

  depends_on = [kubernetes_namespace.monitoring]
}


# 5. OpenTelemetry Collector ì„¤ì¹˜
resource "helm_release" "opentelemetry_collector" {
  name          = "otel-collector"
  repository    = "https://open-telemetry.github.io/opentelemetry-helm-charts"
  chart         = "opentelemetry-collector"
  namespace     = kubernetes_namespace.monitoring.metadata[0].name
  version       = "0.85.0"
  recreate_pods = true

  values = [
    yamlencode({
      # mode : "deployment"         # DaemonSet â†’ Deployment ë³€ê²½
      # replicas : 2                # ì›í•˜ëŠ” ë³µì œ ìˆ˜ ì„¤ì •
      mode : "daemonset"
      config : {
        receivers : {
          otlp : {
            protocols : {
              grpc : {}
              http : {}
            }
          }
        }

        processors : {
          batch : {}
        }


        exporters : {
          loki : { endpoint : "http://loki.fanda-monitoring.svc.cluster.local:3100/loki/api/v1/push" }
          otlphttp : { endpoint : "http://tempo.fanda-monitoring.svc.cluster.local:4318" }
          logging : { verbosity : "detailed" }
        }
        service : {
          pipelines : {
            traces : {
              receivers : ["otlp"]
              processors : ["batch"]
              exporters : ["logging", "otlphttp"]
            }
            metrics : {
              receivers : ["otlp"]
              processors : ["batch"]
              exporters : ["logging"]
            }
          }
        }
      }

      # resources : {
      #   limits : {
      #     cpu : "500m"
      #     memory : "1Gi"
      #   }
      #   requests : {
      #     cpu : "250m"
      #     memory : "512Mi"
      #   }
      # }


    })
  ]

  # helm_release.loki, 
  depends_on = [helm_release.tempo]
}


# 6. Grafana ì„¤ì¹˜
resource "helm_release" "grafana" {
  name          = "grafana"
  repository    = "https://grafana.github.io/helm-charts"
  chart         = "grafana"
  namespace     = kubernetes_namespace.monitoring.metadata[0].name
  version       = "7.3.11"
  recreate_pods = false

  values = [
    yamlencode({
      adminPassword : "Aws9@123" # [ê¶Œì¥] ìš´ì˜ í™˜ê²½ì—ì„œëŠ” Secret ì‚¬ìš©
      serviceAccount : {
        create : false
        name : "cloudwatch-exporter"

      }
      datasources : {
        "datasources.yaml" : {
          apiVersion : 1
          datasources : [
            { name : "Prometheus", type : "prometheus", url : "http://prometheus-stack-prometheus.fanda-monitoring.svc.cluster.local:9090", access : "proxy", isDefault : true },
            { name : "Tempo", type : "tempo", url : "http://tempo.fanda-monitoring.svc.cluster.local:3100", access : "proxy" },
            { name : "Loki", type : "loki", url : "http://loki.fanda-monitoring.svc.cluster.local:3100", access : "proxy" },
            # CloudWatch Metrics
            {
              name : "CloudWatch",
              type : "cloudwatch",
              access : "proxy",
              jsonData : {
                authType : "arn_role", # IRSAë¡œ AWS ê¶Œí•œ ì‚¬ìš©
                defaultRegion : "us-east-1"
              }
            }
          ]
        }
      }
      persistence : {
        enabled : true
        type : "pvc"
        storageClassName : var.storage_class_name
        accessModes : ["ReadWriteOnce"]
        size : "10Gi"
      }
      service : {
        type : "LoadBalancer"
        port : 80
        targetPort : 3000
        # loadBalancerSourceRanges : [
        #   "118.218.200.33/32", # ì‚¬ë¬´ì‹¤
        #   "58.78.119.14/32",   # ì§‘
        #   "211.179.27.76/32",  # ì¹´í˜
        #   "211.60.226.136/32"  # ì •ë¯¼
        # ]
        annotations : {
          "service.beta.kubernetes.io/aws-load-balancer-type" = "nlb",
          "service.beta.kubernetes.io/aws-load-balancer-scheme" : "internet-facing"
        }
      }
    })
  ]
  # helm_release.loki, 
  depends_on = [helm_release.tempo, helm_release.prometheus]
}
